To understand need of protobuff we should understand the evolution of data
evolution of data
-- CSV : comma seperated values format
 file containing a header row representing property names
 each column seperated by ','
 from second line we will have rows having column property values
 advantage:
   easy to read/create for humans, easy to understand if a new dev comes and see the file
 disadvantages:
   but can cause parsing issues in code while reading/writing : sequence of headers and columns indexes are fixed based on read/write code
 also the data type of values has to be inferred in code while reading and parsing the file

-- Relational D.B 
 then came relational D.B solving issues with CSV like datatype inferring by defining fixed data type of columns in tables
 but we can not pass the data so easily to another application via network call using D.B format
 
-- JSON
  it is just a format of represting data each proeprty is seperated by comma and property value pairs are sperated by ':'
  advantage
    can be passed over internet
    can be passed to application of any programming language as we are just representing the data format   
    very good support of serialzation/deserialzation among multiple programming languages
	easily understandable just by looking to humans
  disadvantages
    it is like string notation with duplicate key chars and hence takes a lot of memory and hence slow over the network. serialzation/deserialzation process
    no schema type defined , it can be anything and cause issue while deserialzation
-- PRotobuff
  same like JSon but data will be in bits
  even comments can be written on same .proto file for readability and communication
advantage:
  have a strict schema enforcement, data is in bit format and hence very small in size
  tough for hackers to read the data and hack,
  same .proto file can be used to create pojo for any programming language automatically
  pojo are created automatically via code
  support of schema evolution
 
- data is not passed using field name in protouff
 instead tags are used as size of tag is way lesser than field name and hence char length of message are reduced
 1-15 are used for common non nullable fields as size is 1 byte for these tags
 16-2047 : used for fields whihch are rarely passed or less freequently passed in messages -> 2 bytes of size
 
- proto buff always insert default value for each field
  nulls are not allowed instead a default value is kept for fields whihc are not added in java object 
  default for int32/int64: 0 for string "" for object empty object for array empty array
   it will never pass null but always sent some default empty object/value for fields
   default of enum type is first value present (genrally tagged with 0)
   enum tags starts with 0 and not 1 whihc will be default value of enum when passed empty from source application
 
- a nested message or enum can be used within a message
  this ensures that that type of message or enum can not be used in another .proto file using package import 
  
  
rare scenarios in .proto files config  
 a. options java_package is used to set the package of the class that will be generated by protoc tool
 b. package -> this means the package of the .proto file, this is used to uniquely identify the .proto to be used in another .proto file
 c. option java_multiple_files: 
    if set to true in a .proto file then all the message present in that .proto file will be created as seperate independent classes
	if set to false the other ones may be created as inner class
	 it creates one outer class and keep all the different message in that outer class as nester inner class(static inner class)
	 
Rules to focus while doing data evolution
a. never cahnge the tag of a runnign existing property
b. whenever a new proeprty is addeda always add a new tag
c. whenever a property is to be removed , have the tag and field name reserved so that same tag can not be sued by another new proeprty
d. it supports both forward and backward compatibility
 - in case producer added a new property ad consumer is running old proto file the field will be ignored completely in consumer
 - in case producer removes some proeprty and consumeris running new proto then the default value will be set as empty in consumer
 
Defaults are good for below scenarios
a. no null pointer exception as there will always be empty default values to nth level fo proto messages
b. it helps in forward and backward compatibility without breaking any code in producer or consumer

however this can be tricky as we wont be able to differentiate if the value is actually default or wrong data is set by producer
eg if customer set empty string as firstname in consumer we wont be able to differentiate if that if that is default or actually wrong data is set in producer 

- oneof is an advanced data type in protobuff
	where we can define two or more proeprties in a message out of whihc at once only one will be set
	 if we create object and call setters multiple times
	 the last property will be set to a value and other fields will be set as empty/default values
	 
- main use case of protobuff are services
services are nothing but endpoint apis created and another client can call this services
the main advantage is that once we create a proto file for request message type, response message type and services
 same proto file can be used by server side to create endpoints for the services
and same proto file can be used by client side (in any programming language) to generate client code that calls the main service endpoints exposed
it loos like clietn calls a mehod and internally it calls the server to get the data 